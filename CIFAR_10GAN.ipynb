{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDwxhFDvM78PxVe4QelulF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achillesposiedon/GAN/blob/master/CIFAR_10GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsmLVlubqs90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "596820e2-c325-434a-c220-b00564d5e779"
      },
      "source": [
        "import tensorflow as tf\n",
        "!pip install -q imageio\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt1jbFicq7Aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gk4QSelrImJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "59c0ca7d-a5a6-440d-bb74-637bb6d3e249"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(train1,label),(test,labeltest)=cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096/170498071 [==============================] - 13s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH3UHKOJrVsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "42ff3192-abc0-4120-b751-ab19d7df6404"
      },
      "source": [
        "print(train1.shape)\n",
        "print(label.shape)\n",
        "print(test.shape)\n",
        "print(labeltest.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0E4IgrOraPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train1=train1.reshape(50000,32,32,3).astype('float32')\n",
        "train1=(train1-127.5)/127.5 #range (-1,1)\n",
        "\n",
        "test=test.reshape(10000,32,32,3).astype('float32')\n",
        "test=(test-127.5)/127.5 #range (-1,1)\n",
        "\n",
        "batchsize=256\n",
        "buffersize=50000\n",
        "\n",
        "# Batch and shuffle the data\n",
        "traindata = tf.data.Dataset.from_tensor_slices(train1).shuffle(buffersize).batch(batchsize)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx6Tw8ZCrnKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((8, 8, 256)))\n",
        "    assert model.output_shape == (None, 8, 8, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 8, 8, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 16, 16, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 32, 32, 3)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRTXNSzjr9cj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "a1d1a55c-f36a-4acb-a98f-834b68f69c37"
      },
      "source": [
        "g=generator()\n",
        "g.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16384)             1638400   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16384)             65536     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 8, 8, 128)         819200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 64)        204800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 3)         4800      \n",
            "=================================================================\n",
            "Total params: 2,733,504\n",
            "Trainable params: 2,700,352\n",
            "Non-trainable params: 33,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI5eslTssEhZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "833a44df-3ab9-4f9f-88ff-daa72a9c77e0"
      },
      "source": [
        "#check generator work\n",
        "\n",
        "noise=tf.random.normal([3,100])\n",
        "img=g(noise,training=False)\n",
        "plt.imshow(img[0,:,:,:])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f40c0389438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyFJ2yGzsL6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(32, (5, 5), strides=(3, 3), padding='same',\n",
        "                                     input_shape=[32, 32, 3]),)\n",
        "    \n",
        "    model.add(layers.Conv2D(32, (5, 5), strides=(3, 3), padding='same',\n",
        "                                     ))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    #model.add(layers.Conv2D(64, (5, 5), strides=(3, 3), padding='same'))\n",
        "    #model.add(layers.Conv2D(64, (5, 5), strides=(3, 3), padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))    \n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1024))\n",
        "    model.add(layers.Dense(512))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D6EfMksuaeb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "9187f989-2702-48f2-9197-1ae1a50438d3"
      },
      "source": [
        "d=discriminator()\n",
        "d.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_38 (Conv2D)           (None, 11, 11, 32)        2432      \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 4, 4, 32)          25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 2, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 2, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 2, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              33792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 587,169\n",
            "Trainable params: 587,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiJvEKIKudL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "4a3b7f92-effb-4e6d-8565-03deb5c3dd47"
      },
      "source": [
        "decision=d(img)\n",
        "print(decision)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.00359796]\n",
            " [0.00379451]\n",
            " [0.00199169]], shape=(3, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTASKYxAugaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(realimg, genimg):\n",
        "    real_loss = cross_entropy(tf.ones_like(realimg), realimg)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(genimg), genimg)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(genimg):\n",
        "    return cross_entropy(tf.ones_like(genimg), genimg)\n",
        "\n",
        "goptimizer=tf.keras.optimizers.Adam(1e-4)\n",
        "doptimizer=tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=goptimizer,\n",
        "                                 discriminator_optimizer=doptimizer,\n",
        "                                 generator=g,\n",
        "                                 discriminator=d)\n",
        "\n",
        "epochs=50\n",
        "noisesize=100\n",
        "numgen=12\n",
        "\n",
        "seed=tf.random.normal([numgen,noisesize])\n",
        "\n",
        "@tf.function #for graph\n",
        "def trainhist(images):\n",
        "    noise = tf.random.normal([batchsize, noisesize])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = g(noise, training=True)\n",
        "\n",
        "      real_output = d(images, training=True)\n",
        "      fake_output = d(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, g.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, d.trainable_variables)\n",
        "\n",
        "    goptimizer.apply_gradients(zip(gradients_of_generator, g.trainable_variables))\n",
        "    doptimizer.apply_gradients(zip(gradients_of_discriminator, d.trainable_variables))\n",
        "\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      trainhist(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(g,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(g,\n",
        "                           epochs,\n",
        "                           seed)\n",
        "\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, :] * 127.5 + 127.5)\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNo48NF8vKPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "3a34f411-c3a6-4bc4-c495-838ae149efad"
      },
      "source": [
        "train(traindata, epochs=100)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAACvCAYAAAD+HzLWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACu0lEQVR4nO3dMY7TUBRA0e9MqKAcDYtg/0ugYRVINBR0oykGxHw2EOQoBebmn9PaxX/F1YsUy97mnANoOB19AOB6goUQwUKIYCFEsBAiWAg571yv/+ezXXnfKnOOsc6sdzmnDQshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIYK90evz1/H8/fOYb7+OPgoLEeyNfr58Gy8/voz59vvoo7CQvXc68Rcfnj6O94+fxvbwcPRRWIhgb7SdHsd2ejf8SOFf2nY+hnWXb567YJU5x1hn1ruc03qAEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIXsvEgf+IzYshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyEnHeu1x+DuvjZ+QtWmXOMdWa9yzltWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwULINuc8+gzAlWxYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIOe9crz8GtV153ypzjrHOrHc5pw0LIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCBEshAgWQgQLIYKFEMFCiGAhRLAQIlgIESyECBZCBAshgoUQwUKIYCFEsBAiWAgRLIQIFkIECyGChRDBQohgIUSwECJYCNnmnEefAbiSDQshgoUQwUKIYCFEsBAiWAj5A6gqMdubWRB1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 288x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yRItwWBvLOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}